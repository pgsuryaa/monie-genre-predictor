# -*- coding: utf-8 -*-
"""Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DYo1RvAuQ5LuJWKsh3B_bIha5iP6RYMl
"""

from google.colab import drive
from glob import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import altair as alt
import urllib
import cv2
import random
import scipy
from keras import backend as K
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D

# Function returns genre count
def fnGetGenreCount( aGenre ):
  aCount = []
  for sGenre in aGenre:
    iCount = aGenrelist.count(sGenre)
    aCount.append(iCount)
  return aCount


# Function returns image object from url
def fnUrlToImage(url):
  resp = urllib.request.urlopen(url)
  image = np.asarray(bytearray(resp.read()), dtype="uint8")
  image = cv2.imdecode(image, cv2.IMREAD_COLOR)
  return image


# Function returns creates dataset
def fnGetDataset(train_size,img_size=32):
  print(range(len(list(img_dict.keys()))))
  indices = random.sample(range(len(list(img_dict.keys()))),train_size)
  x = []
  y = []
  x_test = []
  y_test = []
  for i in range(len(list(img_dict.keys()))):
      id_key = int(list(img_dict.keys())[i])
      if i in indices:
          x.append(fnPreprocess(img_dict[list(img_dict.keys())[i]],size=img_size))
          y.append(fnGetGenreForMovie(id_key))
      else:
          x_test.append(fnPreprocess(img_dict[list(img_dict.keys())[i]],size=img_size))
          y_test.append(fnGetGenreForMovie(id_key))
  print('Dataset creation successful')
  return x,y,x_test,y_test


# Function to pre-process image
def fnPreprocess(img,size=32):
    img = scipy.misc.imresize(img,(size,size))
    img = img.astype(np.float32)
    img = (img / 127.5) - 1.
    return img
  

# Function to get genre class of movie
def fnGetGenreForMovie(movie_id):
    y = np.zeros(len(aUniqGenre))
    g = str(dfMovies[dfMovies['imdbId']==movie_id]['Genre'].values[0])
    y[aUniqGenre.index(g)] = 1
    return y   


# Function to create graph
def fnCreateGraph(aUniqGenre):
  x = aUniqGenre
  y = fnGetGenreCount(x)
  plt.fill_between(x,y)
  plt.plot(x, y, color="Skyblue", alpha=0.6)
  print('Create Graph successful')
      

# Function to create image dict
def fnCreateImgDict(img_dict):  
  iSuccess = 0
  iError = 0
  print('Loading images...')
  for aItem in dfMovies.values:
    try:
      img_dict.update({aItem[0]:fnUrlToImage(aItem[5])})
      iSuccess = iSuccess + 1
    except:
      iError = iError + 1
  print('Success no: ' + str(iSuccess))
  print('Error no: ' + str(iError))
  

# Function to create network
def fnCreateNetwork():
  model = Sequential()
  
  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(SIZE,SIZE,3)))
  model.add(MaxPooling2D(pool_size = (2, 2)))
  
  model.add(Conv2D(32, (3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size = (2, 2)))
  
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  
  model.add(Flatten())
  model.add(Dense(128, activation='relu'))

  model.add(Dense(len(aUniqGenre), activation='softmax'))

  model.compile(loss='categorical_crossentropy',
                optimizer=keras.optimizers.Adam(),
                metrics=['accuracy'])
  return model

def fnCreateNW():
  # Initialising the CNN
  classifier = Sequential()
  # Step 1 - Convolution
  classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))
  # Step 2 - Pooling
  classifier.add(MaxPooling2D(pool_size = (2, 2)))
  # Adding a second convolutional layer
  classifier.add(Conv2D(32, (3, 3), activation = 'relu'))
  classifier.add(MaxPooling2D(pool_size = (2, 2)))
  # Step 3 - Flattening
  classifier.add(Flatten())
  # Step 4 - Full connection
  classifier.add(Dense(units = 128, activation = 'relu'))
  classifier.add(Dense(units = 1, activation = 'sigmoid'))
  # Compiling the CNN
  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
  
  return classifier

  
########################################################

img_dict = {}

# Mount google drive to local colab file system
drive.mount('/content/gdrive', force_remount=False)


# Create dataframe from csv file
dfMovies = pd.read_csv("/content/gdrive/My Drive/CSV_Data/MovieGenre.csv",encoding="ISO-8859-1", nrows=10000)
dfMovies = dfMovies.dropna(subset=["Poster", "Genre"])
dfMovies["Genre"] = dfMovies["Genre"].str.split("|", n = 2, expand = True)
aGenrelist = dfMovies["Genre"].values.tolist()
aUniqGenre = list(set(dfMovies["Genre"]))
aUniqGenre = sorted([x for x in aUniqGenre if str(x) != 'nan'])
print('Reading CSV data successful! Entries: ' + str(len(dfMovies)))

fnCreateGraph(aUniqGenre)
fnCreateImgDict(img_dict)
SIZE = 128 
iTrainSize = int(len(dfMovies)*0.8)
x,y,x_test,y_test = fnGetDataset(iTrainSize,img_size=SIZE)
x = np.asarray(x)
y = np.asarray(y)
x_test = np.asarray(x_test)
y_test = np.asarray(y_test)

oModel = fnCreateNetwork()

oModel.fit(x, y,
          batch_size=50,
          epochs=5,
          verbose=1,
          validation_data=(x_test, y_test))

# oModel.fit_generator(x, y,
# steps_per_epoch = 8000,
# epochs = 25,
# validation_data = (x_test, y_test),
# validation_steps = 2000)

score = oModel.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
print(score)